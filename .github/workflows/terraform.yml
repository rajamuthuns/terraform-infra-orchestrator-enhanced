name: Terraform Deploy

on:
  push:
    branches:
      - dev
      - staging
      - production
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment test'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - production
      action:
        description: 'Pipeline action'
        required: true
        default: 'plan-and-apply'
        type: choice
        options:
          - setup-only
          - plan-only
          - plan-and-apply
          - destroy
      skip_setup:
        description: 'Skip setup stage (if backends already exist)'
        required: false
        default: false
        type: boolean
      create_promotion_pr:
        description: 'Create PR to next environment after successful deployment'
        required: false
        default: true
        type: boolean

env:
  TF_VERSION: "1.6.0"
  AWS_DEFAULT_REGION: "us-east-1"

jobs:
  setup-backends:
    name: Setup Common Terraform Backend
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'workflow_dispatch' && github.event.inputs.skip_setup != 'true') ||
      (github.event_name == 'push')
    outputs:
      setup-success: ${{ steps.setup-result.outputs.success }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Configure Git Authentication
        run: |
          git config --global url."https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com/".insteadOf "https://github.com/"
          git config --global credential.helper store
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
          
          mkdir -p ~/.git
          echo "https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com" > ~/.git-credentials
          chmod 600 ~/.git-credentials
          
          echo "GIT_CONFIG_GLOBAL=$HOME/.gitconfig" >> $GITHUB_ENV
          echo "GIT_ASKPASS=echo" >> $GITHUB_ENV
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Determine target environment
        id: target-env
        run: |
          echo "üîß Setup Backend Job Started"
          echo "üìã Event: ${{ github.event_name }}"
          echo "üìã Action: ${{ github.event.inputs.action }}"
          echo "üìã Skip Setup: ${{ github.event.inputs.skip_setup }}"
          
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            ENV="${{ github.event.inputs.environment }}"
          else
            case "${{ github.ref_name }}" in
              "dev") ENV="dev" ;;
              "staging") ENV="staging" ;;
              "production") ENV="production" ;;
              *) ENV="dev" ;;
            esac
          fi
          echo "environment=$ENV" >> $GITHUB_OUTPUT
          echo "‚úÖ Target environment: $ENV"
      - name: Setup common backend configuration
        run: |
          echo "üîß Setting up common backend resources"
          echo "üìã Event: ${{ github.event_name }}"
          echo "üìã Action: ${{ github.event.inputs.action }}"
          
          # Ensure config file exists for shared services account
          if [ ! -f "config/aws-accounts.json" ]; then
            echo "‚ùå config/aws-accounts.json not found"
            echo "This file is required to determine the shared services account for backend resources"
            echo "Please create config/aws-accounts.json with shared_services account configuration"
            exit 1
          fi
          
          # Get shared services account ID from config (controlled by platform team)
          SHARED_SERVICES_ACCOUNT_ID=$(jq -r '.shared_services.account_id' config/aws-accounts.json)
          
          if [ "$SHARED_SERVICES_ACCOUNT_ID" = "null" ] || [ "$SHARED_SERVICES_ACCOUNT_ID" = "REPLACE_WITH_SHARED_SERVICES_ACCOUNT_ID" ]; then
            echo "‚ùå Shared services account ID not configured in config/aws-accounts.json"
            echo "Please update the shared_services.account_id field with the actual shared services account ID"
            echo "This ensures backend resources are created in the correct account controlled by the platform team"
            exit 1
          fi
          
          echo "üìã Shared Services Account (for backend): $SHARED_SERVICES_ACCOUNT_ID"
          echo "üèõÔ∏è This account is controlled by the platform/orchestrator team"
          
          # Use single common resources in shared services account
          COMMON_BUCKET_NAME="terraform-state-central-multi-env"
          COMMON_DYNAMODB_TABLE="terraform-state-locks-common"
          
          echo "üì¶ Common bucket: $COMMON_BUCKET_NAME"
          echo "üóÑÔ∏è Common DynamoDB table: $COMMON_DYNAMODB_TABLE"
          
          # Assume role in shared services account to create backend resources
          SHARED_SERVICES_ROLE_ARN="arn:aws:iam::${SHARED_SERVICES_ACCOUNT_ID}:role/OrganizationAccountAccessRole"
          
          echo "üîê Assuming role in shared services account: $SHARED_SERVICES_ROLE_ARN"
          if SHARED_CREDENTIALS=$(aws sts assume-role \
            --role-arn "$SHARED_SERVICES_ROLE_ARN" \
            --role-session-name "backend-setup-shared-services" \
            --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' \
            --output text 2>&1); then
            
            export AWS_ACCESS_KEY_ID=$(echo $SHARED_CREDENTIALS | cut -d' ' -f1)
            export AWS_SECRET_ACCESS_KEY=$(echo $SHARED_CREDENTIALS | cut -d' ' -f2)
            export AWS_SESSION_TOKEN=$(echo $SHARED_CREDENTIALS | cut -d' ' -f3)
            echo "‚úÖ Successfully assumed role in shared services account"
          else
            echo "‚ùå Failed to assume role in shared services account"
            echo "Error: $SHARED_CREDENTIALS"
            echo "Please ensure:"
            echo "1. The shared services account ID is correct in config/aws-accounts.json"
            echo "2. OrganizationAccountAccessRole exists in the shared services account"
            echo "3. Current credentials have permission to assume the role"
            exit 1
          fi
          
          # Create common S3 bucket if it doesn't exist
          echo "Checking S3 bucket: $COMMON_BUCKET_NAME"
          if aws s3api head-bucket --bucket "$COMMON_BUCKET_NAME" 2>/dev/null; then
            echo "‚úÖ S3 bucket $COMMON_BUCKET_NAME already exists"
          else
            echo "Creating S3 bucket: $COMMON_BUCKET_NAME"
            aws s3api create-bucket --bucket "$COMMON_BUCKET_NAME" --region us-east-1
            aws s3api put-bucket-versioning --bucket "$COMMON_BUCKET_NAME" --versioning-configuration Status=Enabled
            aws s3api put-bucket-encryption --bucket "$COMMON_BUCKET_NAME" --server-side-encryption-configuration '{
              "Rules": [{
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }]
            }'
            aws s3api put-public-access-block --bucket "$COMMON_BUCKET_NAME" --public-access-block-configuration \
              "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
            echo "‚úÖ S3 bucket created and configured"
          fi
          
          # Create common DynamoDB table if it doesn't exist
          echo "Checking DynamoDB table: $COMMON_DYNAMODB_TABLE"
          if aws dynamodb describe-table --table-name "$COMMON_DYNAMODB_TABLE" 2>/dev/null; then
            echo "‚úÖ DynamoDB table $COMMON_DYNAMODB_TABLE already exists"
          else
            echo "Creating DynamoDB table: $COMMON_DYNAMODB_TABLE"
            aws dynamodb create-table \
              --table-name "$COMMON_DYNAMODB_TABLE" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --sse-specification Enabled=true
            
            # Wait for table to be active
            echo "Waiting for DynamoDB table to become active..."
            aws dynamodb wait table-exists --table-name "$COMMON_DYNAMODB_TABLE"
            echo "‚úÖ DynamoDB table created and active"
          fi
          
          # Update bucket policy for cross-account access from environment accounts
          echo "Setting up cross-account bucket policy..."
          
          # Build list of account ARNs that need access to the backend
          ACCOUNT_ARNS="\"arn:aws:iam::${SHARED_SERVICES_ACCOUNT_ID}:root\""
          
          # Add current user/account for administrative access
          CURRENT_USER_ARN=$(aws sts get-caller-identity --query Arn --output text)
          CURRENT_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ACCOUNT_ARNS="${ACCOUNT_ARNS},\"${CURRENT_USER_ARN}\""
          ACCOUNT_ARNS="${ACCOUNT_ARNS},\"arn:aws:iam::${CURRENT_ACCOUNT_ID}:root\""
          echo "  - Added access for current user: $CURRENT_USER_ARN"
          echo "  - Added access for current account: $CURRENT_ACCOUNT_ID"
          
          # Add master account (345918514280) for terraform init access
          MASTER_ACCOUNT_ID="345918514280"
          ACCOUNT_ARNS="${ACCOUNT_ARNS},\"arn:aws:iam::${MASTER_ACCOUNT_ID}:root\""
          echo "  - Added access for master account: $MASTER_ACCOUNT_ID"
          
          # Add environment accounts from config
          for env in $(jq -r 'keys[]' config/aws-accounts.json); do
            if [ "$env" != "shared_services" ]; then
              account_id=$(jq -r ".${env}.account_id" config/aws-accounts.json)
              if [ "$account_id" != "null" ] && [ "$account_id" != "REPLACE_WITH_PRODUCTION_ACCOUNT_ID" ]; then
                ACCOUNT_ARNS="${ACCOUNT_ARNS},\"arn:aws:iam::${account_id}:role/OrganizationAccountAccessRole\""
                # Also add root access for the account (for broader access patterns)
                ACCOUNT_ARNS="${ACCOUNT_ARNS},\"arn:aws:iam::${account_id}:root\""
                echo "  - Added access for $env account: $account_id (via OrganizationAccountAccessRole and root)"
              fi
            fi
          done
          
          # Apply bucket policy for cross-account and cross-region access
          aws s3api put-bucket-policy --bucket "$COMMON_BUCKET_NAME" --policy "{
            \"Version\": \"2012-10-17\",
            \"Statement\": [
              {
                \"Sid\": \"AllowCrossAccountAccess\",
                \"Effect\": \"Allow\",
                \"Principal\": {
                  \"AWS\": [${ACCOUNT_ARNS}]
                },
                \"Action\": [
                  \"s3:GetObject\",
                  \"s3:PutObject\",
                  \"s3:DeleteObject\",
                  \"s3:ListBucket\",
                  \"s3:GetBucketLocation\",
                  \"s3:ListBucketVersions\"
                ],
                \"Resource\": [
                  \"arn:aws:s3:::${COMMON_BUCKET_NAME}\",
                  \"arn:aws:s3:::${COMMON_BUCKET_NAME}/*\"
                ]
              }
            ]
          }"
          
          echo "‚úÖ Cross-account bucket policy configured"
          
          # Apply DynamoDB resource policy for cross-account access
          echo "Setting up DynamoDB resource policy for cross-account access..."
          
          # Build list of account ARNs for DynamoDB access (reuse the same list)
          DYNAMODB_ACCOUNT_ARNS="${ACCOUNT_ARNS}"
          
          # Ensure master account is included for DynamoDB access
          MASTER_ACCOUNT_ID="345918514280"
          DYNAMODB_ACCOUNT_ARNS="${DYNAMODB_ACCOUNT_ARNS},\"arn:aws:iam::${MASTER_ACCOUNT_ID}:root\""
          
          # Apply DynamoDB resource policy
          aws dynamodb put-resource-policy \
            --resource-arn "arn:aws:dynamodb:us-east-1:${SHARED_SERVICES_ACCOUNT_ID}:table/${COMMON_DYNAMODB_TABLE}" \
            --policy "{
              \"Version\": \"2012-10-17\",
              \"Statement\": [
                {
                  \"Sid\": \"AllowCrossAccountDynamoDBAccess\",
                  \"Effect\": \"Allow\",
                  \"Principal\": {
                    \"AWS\": [${DYNAMODB_ACCOUNT_ARNS}]
                  },
                  \"Action\": [
                    \"dynamodb:GetItem\",
                    \"dynamodb:PutItem\",
                    \"dynamodb:DeleteItem\",
                    \"dynamodb:DescribeTable\"
                  ],
                  \"Resource\": \"arn:aws:dynamodb:us-east-1:${SHARED_SERVICES_ACCOUNT_ID}:table/${COMMON_DYNAMODB_TABLE}\"
                }
              ]
            }" 2>/dev/null && echo "‚úÖ DynamoDB resource policy configured" || {
            echo "‚ö†Ô∏è DynamoDB resource policy not supported in this region or account"
            echo "üí° Alternative: Ensure OrganizationAccountAccessRole in environment accounts has DynamoDB permissions"
            echo "   Required permissions: dynamodb:GetItem, dynamodb:PutItem, dynamodb:DeleteItem, dynamodb:DescribeTable"
            echo "   Resource: arn:aws:dynamodb:us-east-1:${SHARED_SERVICES_ACCOUNT_ID}:table/${COMMON_DYNAMODB_TABLE}"
          }
          
          # Create common backend configuration file (same for all environments)
          cat > "shared/backend-common.hcl" << EOF
          # Common backend configuration for all environments
          # Workspaces handle environment separation
          bucket         = "${COMMON_BUCKET_NAME}"
          key            = "terraform.tfstate"
          region         = "us-east-1"
          dynamodb_table = "${COMMON_DYNAMODB_TABLE}"
          encrypt        = true
          
          # Workspace configuration - creates separate state files per workspace
          workspace_key_prefix = "environments"
          
          
          skip_credentials_validation = false
          skip_metadata_api_check = false
          skip_region_validation = false
          use_path_style = false
          max_retries = 5
          EOF
          
          echo "‚úÖ Common backend setup completed"
          echo "üì¶ Bucket: $COMMON_BUCKET_NAME (in shared services account: $SHARED_SERVICES_ACCOUNT_ID)"
          echo "üóÑÔ∏è DynamoDB: $COMMON_DYNAMODB_TABLE (in shared services account: $SHARED_SERVICES_ACCOUNT_ID)"
          echo "üè¢ Workspaces will handle environment separation"
          echo "üèõÔ∏è Backend resources controlled by platform team via config/aws-accounts.json"
          echo "üìÑ Common backend config created: shared/backend-common.hcl"
      - name: Upload backend artifacts
        uses: actions/upload-artifact@v4
        with:
          name: terraform-backends
          path: shared/backend-common.hcl
          retention-days: 7

      - name: Set setup success output
        id: setup-result
        run: echo "success=true" >> $GITHUB_OUTPUT

  determine-environment:
    name: Determine Environment
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      tfvars-file: ${{ steps.env.outputs.tfvars-file }}
      needs-approval: ${{ steps.env.outputs.needs-approval }}
    steps:
      - name: Determine environment from branch or input
        id: env
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            ENV="${{ github.event.inputs.environment }}"
          else
            case "${{ github.ref_name }}" in
              "dev") ENV="dev" ;;
              "staging") ENV="staging" ;;
              "production") ENV="production" ;;
              *) ENV="dev" ;;
            esac
          fi
          
          echo "environment=$ENV" >> $GITHUB_OUTPUT
          
          case "$ENV" in
            "dev")
              echo "tfvars-file=dev-terraform.tfvars" >> $GITHUB_OUTPUT
              echo "needs-approval=false" >> $GITHUB_OUTPUT
              ;;
            "staging")
              echo "tfvars-file=stg-terraform.tfvars" >> $GITHUB_OUTPUT
              echo "needs-approval=true" >> $GITHUB_OUTPUT
              ;;
            "production")
              echo "tfvars-file=prod-terraform.tfvars" >> $GITHUB_OUTPUT
              echo "needs-approval=true" >> $GITHUB_OUTPUT
              ;;
          esac
          
          echo "Determined environment: $ENV"
  terraform-plan:
    name: Terraform Plan - ${{ needs.determine-environment.outputs.environment }}
    runs-on: ubuntu-latest
    needs: [setup-backends, determine-environment]
    if: |
      always() && 
      (
        (github.event_name == 'workflow_dispatch' && (github.event.inputs.action == 'plan-and-apply' || github.event.inputs.action == 'plan-only')) ||
        (github.event_name == 'push')
      ) &&
      (
        (needs.setup-backends.result == 'success') ||
        (needs.setup-backends.result == 'skipped')
      )
    outputs:
      plan-success: ${{ steps.plan-result.outputs.success }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Configure Git Authentication
        run: |
          git config --global url."https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com/".insteadOf "https://github.com/"
          git config --global credential.helper store
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
          
          mkdir -p ~/.git
          echo "https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com" > ~/.git-credentials
          chmod 600 ~/.git-credentials
          
          echo "GIT_CONFIG_GLOBAL=$HOME/.gitconfig" >> $GITHUB_ENV
          echo "GIT_ASKPASS=echo" >> $GITHUB_ENV
      - name: Download backend artifacts
        if: needs.setup-backends.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: terraform-backends
          path: shared/
        continue-on-error: true

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Get target account info from tfvars
        run: |
          TFVARS_FILE="tfvars/${{ needs.determine-environment.outputs.tfvars-file }}"
          echo "üìã Reading account info from: $TFVARS_FILE"
          
          if [ ! -f "$TFVARS_FILE" ]; then
            echo "‚ùå Tfvars file not found: $TFVARS_FILE"
            exit 1
          fi
          
          # Extract account_id from tfvars file
          TARGET_ACCOUNT_ID=$(grep -E '^account_id\s*=' "$TFVARS_FILE" | sed 's/.*=\s*"\([^"]*\)".*/\1/' | tr -d ' ')
          
          if [ -z "$TARGET_ACCOUNT_ID" ]; then
            echo "‚ö†Ô∏è No account_id found in $TFVARS_FILE, using current account"
            TARGET_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          fi
          
          echo "üìã Target Account ID: $TARGET_ACCOUNT_ID"
          echo "üìã Environment: ${{ needs.determine-environment.outputs.environment }}"
          
          # For common backend approach, we don't need to assume roles
          # All environments use the same backend in the current account
          echo "‚úÖ Using common backend approach - no role assumption needed"
      - name: Assume target environment role for deployment
        run: |
          TFVARS_FILE="tfvars/${{ needs.determine-environment.outputs.tfvars-file }}"
          echo "üìã Reading target account info from: $TFVARS_FILE"
          
          # Extract account_id from tfvars file
          TARGET_ACCOUNT_ID=$(grep -E '^account_id\s*=' "$TFVARS_FILE" | sed 's/.*=\s*"\([^"]*\)".*/\1/' | tr -d ' ')
          
          if [ -z "$TARGET_ACCOUNT_ID" ]; then
            echo "‚ö†Ô∏è No account_id found in $TFVARS_FILE, using current account"
            TARGET_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          fi
          
          echo "üìã Target Account ID: $TARGET_ACCOUNT_ID"
          echo "üìã Environment: ${{ needs.determine-environment.outputs.environment }}"
          
          # Get current account to check if we need to assume a role
          CURRENT_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          
          if [ "$TARGET_ACCOUNT_ID" != "$CURRENT_ACCOUNT_ID" ]; then
            echo "üîê Assuming role in target environment account: $TARGET_ACCOUNT_ID"
            
            TARGET_ROLE_ARN="arn:aws:iam::${TARGET_ACCOUNT_ID}:role/OrganizationAccountAccessRole"
            
            if TARGET_CREDENTIALS=$(aws sts assume-role \
              --role-arn "$TARGET_ROLE_ARN" \
              --role-session-name "terraform-deployment-${{ github.run_id }}" \
              --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' \
              --output text 2>&1); then
              
              # Store target account credentials for deployment operations
              echo "AWS_ACCESS_KEY_ID=$(echo $TARGET_CREDENTIALS | cut -d' ' -f1)" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=$(echo $TARGET_CREDENTIALS | cut -d' ' -f2)" >> $GITHUB_ENV
              echo "AWS_SESSION_TOKEN=$(echo $TARGET_CREDENTIALS | cut -d' ' -f3)" >> $GITHUB_ENV
              
              echo "‚úÖ Successfully assumed role in target environment account"
            else
              echo "‚ùå Failed to assume role in target environment account: $TARGET_CREDENTIALS"
              echo "Please ensure:"
              echo "1. The target account ID is correct in $TFVARS_FILE"
              echo "2. OrganizationAccountAccessRole exists in the target account"
              echo "3. Current credentials have permission to assume the role"
              exit 1
            fi
          else
            echo "‚úÖ Already in target account, no role assumption needed"
          fi

      - name: Check backend configuration
        run: |
          BACKEND_FILE="shared/backend-common.hcl"
          if [ ! -f "$BACKEND_FILE" ]; then
            echo "‚ùå Common backend configuration file not found: $BACKEND_FILE"
            echo "This usually means the setup stage was skipped or failed."
            echo "Available backend files:"
            ls -la shared/backend-*.hcl 2>/dev/null || echo "No backend files found"
            exit 1
          fi
          
          echo "‚úÖ Common backend configuration looks good:"
          cat "$BACKEND_FILE"
          echo "üè¢ Environment isolation will be handled by workspace: ${{ needs.determine-environment.outputs.environment }}"
      - name: Terraform Init with Master Account
        run: |
          # Use master account credentials from GitHub secrets for backend access
          export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
          export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          export AWS_SESSION_TOKEN="${{ secrets.AWS_SESSION_TOKEN }}"
          
          echo "üîß Initializing Terraform with master account credentials..."
          echo "üìã Backend account: $(aws sts get-caller-identity --query Account --output text)"
          
          # Initialize Terraform with shared services backend
          terraform init -backend-config=shared/backend-common.hcl
        env:
          GITHUB_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}
          GIT_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Terraform Workspace
        run: |
          echo "Setting up workspace: ${{ needs.determine-environment.outputs.environment }}"
          if terraform workspace list | grep -q "^\s*${{ needs.determine-environment.outputs.environment }}\s*$"; then
            echo "Workspace '${{ needs.determine-environment.outputs.environment }}' already exists, selecting it"
            terraform workspace select ${{ needs.determine-environment.outputs.environment }}
          else
            echo "Creating new workspace: ${{ needs.determine-environment.outputs.environment }}"
            terraform workspace new ${{ needs.determine-environment.outputs.environment }}
          fi
      - name: Terraform Plan
        id: plan
        run: |
          if [ ! -f tfvars/${{ needs.determine-environment.outputs.tfvars-file }} ]; then
            echo "Error: tfvars file not found: tfvars/${{ needs.determine-environment.outputs.tfvars-file }}"
            exit 1
          fi
          
          # Use master account credentials for state lock access
          export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
          export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          export AWS_SESSION_TOKEN="${{ secrets.AWS_SESSION_TOKEN }}"
          
          terraform plan -var-file=tfvars/${{ needs.determine-environment.outputs.tfvars-file }} -out=tfplan
          
          terraform show -no-color tfplan > plan-output.txt
          echo "## Terraform Plan Summary" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ needs.determine-environment.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "**Tfvars File:** ${{ needs.determine-environment.outputs.tfvars-file }}" >> $GITHUB_STEP_SUMMARY
      - name: Upload plan artifacts
        uses: actions/upload-artifact@v4
        with:
          name: tfplan-${{ needs.determine-environment.outputs.environment }}
          path: |
            tfplan
            plan-output.txt
          retention-days: 7

      - name: Set plan success output
        id: plan-result
        run: echo "success=true" >> $GITHUB_OUTPUT

  deploy:
    name: Deploy - ${{ needs.determine-environment.outputs.environment }}
    runs-on: ubuntu-latest
    needs: [setup-backends, determine-environment, terraform-plan]
    if: |
      always() && 
      needs.terraform-plan.outputs.plan-success == 'true' &&
      (
        (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'plan-and-apply') ||
        (github.event_name == 'push')
      ) &&
      (github.event_name != 'workflow_dispatch' || github.event.inputs.action != 'plan-only')
    environment: 
      name: ${{ needs.determine-environment.outputs.environment }}
    outputs:
      deploy-success: ${{ steps.apply-result.outputs.success }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Configure Git Authentication
        run: |
          git config --global url."https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com/".insteadOf "https://github.com/"
          git config --global credential.helper store
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
          
          mkdir -p ~/.git
          echo "https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com" > ~/.git-credentials
          chmod 600 ~/.git-credentials
          
          echo "GIT_CONFIG_GLOBAL=$HOME/.gitconfig" >> $GITHUB_ENV
          echo "GIT_ASKPASS=echo" >> $GITHUB_ENV
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Download backend artifacts
        if: needs.setup-backends.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: terraform-backends
          path: shared/
        continue-on-error: true

      - name: Download plan artifacts
        uses: actions/download-artifact@v4
        with:
          name: tfplan-${{ needs.determine-environment.outputs.environment }}
          path: ./

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Assume target environment role for deployment
        run: |
          TFVARS_FILE="tfvars/${{ needs.determine-environment.outputs.tfvars-file }}"
          echo "üìã Reading target account info from: $TFVARS_FILE"
          
          # Extract account_id from tfvars file
          TARGET_ACCOUNT_ID=$(grep -E '^account_id\s*=' "$TFVARS_FILE" | sed 's/.*=\s*"\([^"]*\)".*/\1/' | tr -d ' ')
          
          if [ -z "$TARGET_ACCOUNT_ID" ]; then
            echo "‚ö†Ô∏è No account_id found in $TFVARS_FILE, using current account"
            TARGET_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          fi
          
          echo "üìã Target Account ID: $TARGET_ACCOUNT_ID"
          echo "üìã Environment: ${{ needs.determine-environment.outputs.environment }}"
          
          # Get current account to check if we need to assume a role
          CURRENT_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          
          if [ "$TARGET_ACCOUNT_ID" != "$CURRENT_ACCOUNT_ID" ]; then
            echo "üîê Assuming role in target environment account: $TARGET_ACCOUNT_ID"
            
            TARGET_ROLE_ARN="arn:aws:iam::${TARGET_ACCOUNT_ID}:role/OrganizationAccountAccessRole"
            
            if TARGET_CREDENTIALS=$(aws sts assume-role \
              --role-arn "$TARGET_ROLE_ARN" \
              --role-session-name "terraform-deployment-${{ github.run_id }}" \
              --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' \
              --output text 2>&1); then
              
              # Store target account credentials for deployment operations
              echo "AWS_ACCESS_KEY_ID=$(echo $TARGET_CREDENTIALS | cut -d' ' -f1)" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=$(echo $TARGET_CREDENTIALS | cut -d' ' -f2)" >> $GITHUB_ENV
              echo "AWS_SESSION_TOKEN=$(echo $TARGET_CREDENTIALS | cut -d' ' -f3)" >> $GITHUB_ENV
              
              echo "‚úÖ Successfully assumed role in target environment account"
            else
              echo "‚ùå Failed to assume role in target environment account: $TARGET_CREDENTIALS"
              echo "Please ensure:"
              echo "1. The target account ID is correct in $TFVARS_FILE"
              echo "2. OrganizationAccountAccessRole exists in the target account"
              echo "3. Current credentials have permission to assume the role"
              exit 1
            fi
          else
            echo "‚úÖ Already in target account, no role assumption needed"
          fi
      - name: Check backend configuration
        run: |
          BACKEND_FILE="shared/backend-common.hcl"
          if [ ! -f "$BACKEND_FILE" ]; then
            echo "‚ùå Common backend configuration file not found: $BACKEND_FILE"
            echo "Available backend files:"
            ls -la shared/backend-*.hcl 2>/dev/null || echo "No backend files found"
            exit 1
          fi
          
          echo "‚úÖ Common backend configuration looks good:"
          cat "$BACKEND_FILE"
          echo "üè¢ Environment isolation will be handled by workspace: ${{ needs.determine-environment.outputs.environment }}"
      - name: Terraform Init with Master Account
        run: |
          # Use master account credentials from GitHub secrets for backend access
          export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
          export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          export AWS_SESSION_TOKEN="${{ secrets.AWS_SESSION_TOKEN }}"
          
          echo "üîß Initializing Terraform with master account credentials..."
          echo "üìã Backend account: $(aws sts get-caller-identity --query Account --output text)"
          
          # Initialize Terraform with shared services backend
          terraform init -backend-config=shared/backend-common.hcl
        env:
          GITHUB_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}
          GIT_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Terraform Workspace
        run: |
          echo "Setting up workspace: ${{ needs.determine-environment.outputs.environment }}"
          if terraform workspace list | grep -q "^\s*${{ needs.determine-environment.outputs.environment }}\s*$"; then
            echo "Workspace '${{ needs.determine-environment.outputs.environment }}' already exists, selecting it"
            terraform workspace select ${{ needs.determine-environment.outputs.environment }}
          else
            echo "Creating new workspace: ${{ needs.determine-environment.outputs.environment }}"
            terraform workspace new ${{ needs.determine-environment.outputs.environment }}
          fi
      - name: Terraform Apply
        id: apply
        run: |
          if [ -f tfplan ]; then
            echo "Using existing plan file..."
            terraform apply -auto-approve tfplan
          else
            echo "No plan file found, running apply with tfvars..."
            terraform apply -auto-approve -var-file=tfvars/${{ needs.determine-environment.outputs.tfvars-file }}
          fi
      - name: Get outputs
        id: outputs
        run: |
          terraform output -json > outputs.json
          
          ALB_ENDPOINTS=$(terraform output -json alb_endpoints 2>/dev/null || echo '{}')
          if [ "$ALB_ENDPOINTS" != "{}" ]; then
            FIRST_ALB_URL=$(echo $ALB_ENDPOINTS | jq -r 'to_entries | .[0].value // empty')
            if [ -n "$FIRST_ALB_URL" ]; then
              echo "alb_url=http://$FIRST_ALB_URL" >> $GITHUB_OUTPUT
            fi
          fi
      - name: Upload outputs
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs-${{ needs.determine-environment.outputs.environment }}
          path: outputs.json
          retention-days: 30

      - name: Set deploy success output
        id: apply-result
        run: echo "success=true" >> $GITHUB_OUTPUT

  destroy-approval:
    name: Destroy Approval Required
    runs-on: ubuntu-latest
    needs: [setup-backends, determine-environment]
    if: |
      always() && 
      github.event_name == 'workflow_dispatch' && 
      github.event.inputs.action == 'destroy' &&
      (needs.setup-backends.result == 'success' || needs.setup-backends.result == 'skipped')
    environment: 
      name: destroy-${{ needs.determine-environment.outputs.environment }}
    outputs:
      approved: ${{ steps.approval.outputs.approved }}
    steps:
      - name: Destroy Approval Required
        id: approval
        run: |
          echo "## ‚ö†Ô∏è DESTROY CONFIRMATION REQUIRED" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ needs.determine-environment.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "**Action:** DESTROY ALL INFRASTRUCTURE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ‚ö†Ô∏è WARNING" >> $GITHUB_STEP_SUMMARY
          echo "This will **PERMANENTLY DELETE** all infrastructure in the ${{ needs.determine-environment.outputs.environment }} environment!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üîç What will be destroyed:" >> $GITHUB_STEP_SUMMARY
          echo "- All EC2 instances" >> $GITHUB_STEP_SUMMARY
          echo "- All Load Balancers" >> $GITHUB_STEP_SUMMARY
          echo "- All associated resources" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ‚úÖ To proceed with destroy:" >> $GITHUB_STEP_SUMMARY
          echo "1. This step requires manual approval in GitHub" >> $GITHUB_STEP_SUMMARY
          echo "2. Go to Repository Settings ‚Üí Environments" >> $GITHUB_STEP_SUMMARY
          echo "3. Create environment: destroy-${{ needs.determine-environment.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "4. Add required reviewers (yourself)" >> $GITHUB_STEP_SUMMARY
          echo "5. Then approve this deployment to proceed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**This action cannot be undone!**" >> $GITHUB_STEP_SUMMARY
          echo "approved=true" >> $GITHUB_OUTPUT
  terraform-destroy:
    name: Terraform Destroy - ${{ needs.determine-environment.outputs.environment }}
    runs-on: ubuntu-latest
    needs: [setup-backends, determine-environment, destroy-approval]
    if: |
      always() && 
      needs.destroy-approval.outputs.approved == 'true' &&
      github.event_name == 'workflow_dispatch' && 
      github.event.inputs.action == 'destroy'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Configure Git Authentication
        run: |
          git config --global url."https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com/".insteadOf "https://github.com/"
          git config --global credential.helper store
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
          
          mkdir -p ~/.git
          echo "https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com" > ~/.git-credentials
          chmod 600 ~/.git-credentials
          
          echo "GIT_CONFIG_GLOBAL=$HOME/.gitconfig" >> $GITHUB_ENV
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Download backend artifacts
        if: needs.setup-backends.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: terraform-backends
          path: shared/
        continue-on-error: true

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Assume target account role
        run: |
          TFVARS_FILE="tfvars/${{ needs.determine-environment.outputs.tfvars-file }}"
          echo "üìã Reading account info from: $TFVARS_FILE"
          
          # Extract account_id from tfvars file
          TARGET_ACCOUNT_ID=$(grep -E '^account_id\s*=' "$TFVARS_FILE" | sed 's/.*=\s*"\([^"]*\)".*/\1/' | tr -d ' ')
          
          if [ -z "$TARGET_ACCOUNT_ID" ]; then
            echo "‚ö†Ô∏è No account_id found in $TFVARS_FILE, using current account"
            TARGET_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          fi
          
          echo "üìã Target Account ID: $TARGET_ACCOUNT_ID"
          echo "üìã Environment: ${{ needs.determine-environment.outputs.environment }}"
          echo "‚úÖ Using common backend approach - no role assumption needed"
      - name: Check backend configuration
        run: |
          BACKEND_FILE="shared/backend-common.hcl"
          if [ ! -f "$BACKEND_FILE" ]; then
            echo "‚ùå Common backend configuration file not found: $BACKEND_FILE"
            echo "Available backend files:"
            ls -la shared/backend-*.hcl 2>/dev/null || echo "No backend files found"
            exit 1
          fi
          
          echo "‚úÖ Common backend configuration looks good:"
          cat "$BACKEND_FILE"
          echo "üè¢ Environment isolation will be handled by workspace: ${{ needs.determine-environment.outputs.environment }}"
      - name: Terraform Init
        run: |
          terraform init -backend-config=shared/backend-common.hcl
        env:
          GITHUB_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}
          GIT_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Terraform Workspace
        run: |
          echo "Setting up workspace: ${{ needs.determine-environment.outputs.environment }}"
          if terraform workspace list | grep -q "^\s*${{ needs.determine-environment.outputs.environment }}\s*$"; then
            echo "Workspace '${{ needs.determine-environment.outputs.environment }}' already exists, selecting it"
            terraform workspace select ${{ needs.determine-environment.outputs.environment }}
          else
            echo "Creating new workspace: ${{ needs.determine-environment.outputs.environment }}"
            terraform workspace new ${{ needs.determine-environment.outputs.environment }}
          fi
      - name: Confirm Destroy Action
        run: |
          echo "üö® DESTROY ACTION CONFIRMED"
          echo "Environment: ${{ needs.determine-environment.outputs.environment }}"
          echo "Tfvars file: ${{ needs.determine-environment.outputs.tfvars-file }}"
          echo "This will destroy ALL resources in the ${{ needs.determine-environment.outputs.environment }} environment!"
      - name: Terraform Destroy
        run: |
          if [ ! -f tfvars/${{ needs.determine-environment.outputs.tfvars-file }} ]; then
            echo "Error: tfvars file not found: tfvars/${{ needs.determine-environment.outputs.tfvars-file }}"
            exit 1
          fi
          
          echo "üóëÔ∏è Starting terraform destroy..."
          terraform destroy -auto-approve -var-file=tfvars/${{ needs.determine-environment.outputs.tfvars-file }}
          echo "‚úÖ Terraform destroy completed successfully"
  cleanup-and-retry-destroy:
    name: Cleanup ALB Logs and Retry Destroy
    runs-on: ubuntu-latest
    needs: [setup-backends, determine-environment, destroy-approval, terraform-destroy]
    if: |
      always() && 
      needs.destroy-approval.outputs.approved == 'true' &&
      needs.terraform-destroy.result == 'failure' &&
      github.event_name == 'workflow_dispatch' && 
      github.event.inputs.action == 'destroy'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Configure Git Authentication
        run: |
          git config --global url."https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com/".insteadOf "https://github.com/"
          git config --global credential.helper store
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
          
          mkdir -p ~/.git
          echo "https://${{ secrets.PRIVATE_REPO_TOKEN }}@github.com" > ~/.git-credentials
          chmod 600 ~/.git-credentials
          
          echo "GIT_CONFIG_GLOBAL=$HOME/.gitconfig" >> $GITHUB_ENV
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Download backend artifacts
        if: needs.setup-backends.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: terraform-backends
          path: shared/
        continue-on-error: true

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Assume target account role
        run: |
          TFVARS_FILE="tfvars/${{ needs.determine-environment.outputs.tfvars-file }}"
          echo "üìã Reading account info from: $TFVARS_FILE"
          
          # Extract account_id from tfvars file
          TARGET_ACCOUNT_ID=$(grep -E '^account_id\s*=' "$TFVARS_FILE" | sed 's/.*=\s*"\([^"]*\)".*/\1/' | tr -d ' ')
          
          if [ -z "$TARGET_ACCOUNT_ID" ]; then
            echo "‚ö†Ô∏è No account_id found in $TFVARS_FILE, using current account"
            TARGET_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          fi
          
          echo "üìã Target Account ID: $TARGET_ACCOUNT_ID"
          echo "‚úÖ Using common backend approach - no role assumption needed"
          
          TARGET_CREDENTIALS=$(aws sts assume-role \
            --role-arn $TARGET_ROLE_ARN \
            --role-session-name github-actions-cleanup-${{ needs.determine-environment.outputs.environment }}-${{ github.run_id }} \
            --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' \
            --output text)
          
          echo "AWS_ACCESS_KEY_ID=$(echo $TARGET_CREDENTIALS | cut -d' ' -f1)" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=$(echo $TARGET_CREDENTIALS | cut -d' ' -f2)" >> $GITHUB_ENV
          echo "AWS_SESSION_TOKEN=$(echo $TARGET_CREDENTIALS | cut -d' ' -f3)" >> $GITHUB_ENV
      - name: Cleanup ALB access log buckets
        run: |
          echo "üßπ Terraform destroy failed - cleaning up ALB access log buckets"
          echo "Environment: ${{ needs.determine-environment.outputs.environment }}"
          echo ""
          
          chmod +x scripts/cleanup-alb-logs.sh
          bash scripts/cleanup-alb-logs.sh "${{ needs.determine-environment.outputs.environment }}"
      - name: Retry Terraform Destroy
        run: |
          echo "üîÑ Retrying Terraform destroy after ALB log cleanup..."
          
          # Initialize Terraform
          terraform init -backend-config=shared/backend-common.hcl
          
          # Select workspace
          echo "Setting up workspace: ${{ needs.determine-environment.outputs.environment }}"
          if terraform workspace list | grep -q "^\s*${{ needs.determine-environment.outputs.environment }}\s*$"; then
            echo "Workspace '${{ needs.determine-environment.outputs.environment }}' already exists, selecting it"
            terraform workspace select ${{ needs.determine-environment.outputs.environment }}
          else
            echo "Creating new workspace: ${{ needs.determine-environment.outputs.environment }}"
            terraform workspace new ${{ needs.determine-environment.outputs.environment }}
          fi
          
          # Retry destroy
          if [ ! -f tfvars/${{ needs.determine-environment.outputs.tfvars-file }} ]; then
            echo "Error: tfvars file not found: tfvars/${{ needs.determine-environment.outputs.tfvars-file }}"
            exit 1
          fi
          
          echo "üóëÔ∏è Retrying terraform destroy..."
          terraform destroy -auto-approve -var-file=tfvars/${{ needs.determine-environment.outputs.tfvars-file }}
          echo "‚úÖ Terraform destroy retry completed successfully"
        env:
          GITHUB_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}
          GIT_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Force cleanup remaining resources (if retry still fails)
        if: failure()
        run: |
          echo "‚ö†Ô∏è Terraform destroy retry failed. Attempting additional cleanup..."
          
          # Try destroy with -refresh=false to skip state refresh
          terraform destroy -auto-approve -var-file=tfvars/${{ needs.determine-environment.outputs.tfvars-file }} -refresh=false || true
          
          # Try targeted destroy of common problematic resources
          echo "üéØ Attempting targeted destroy of ALB resources..."
          terraform destroy -auto-approve -var-file=tfvars/${{ needs.determine-environment.outputs.tfvars-file }} -target=module.alb || true
          
          echo "üéØ Attempting targeted destroy of EC2 resources..."
          terraform destroy -auto-approve -var-file=tfvars/${{ needs.determine-environment.outputs.tfvars-file }} -target=module.ec2_instance || true
        env:
          GITHUB_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}
          GIT_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}
        continue-on-error: true

      - name: Cleanup summary
        if: always()
        run: |
          echo "## üßπ ALB Log Cleanup and Destroy Retry Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ needs.determine-environment.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "**Reason:** Terraform destroy failed due to non-empty S3 buckets" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Actions Taken:" >> $GITHUB_STEP_SUMMARY
          echo "- üßπ Cleaned up ALB access log buckets" >> $GITHUB_STEP_SUMMARY
          echo "- üîÑ Retried Terraform destroy" >> $GITHUB_STEP_SUMMARY
          if [ "${{ job.status }}" == "failure" ]; then
            echo "- ‚ö†Ô∏è Attempted force destroy of remaining resources" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚ö†Ô∏è Manual Cleanup May Be Required" >> $GITHUB_STEP_SUMMARY
            echo "Some resources may still exist in AWS. Please check the AWS Console and clean up manually if needed." >> $GITHUB_STEP_SUMMARY
          else
            echo "- ‚úÖ Successfully destroyed all infrastructure" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚ÑπÔ∏è **Note:** Terraform state and DynamoDB tables were preserved" >> $GITHUB_STEP_SUMMARY
  production-approval:
    name: Production Terraform Apply Approval
    runs-on: ubuntu-latest
    needs: [determine-environment, terraform-plan]
    if: |
      needs.determine-environment.outputs.environment == 'production' &&
      needs.terraform-plan.outputs.plan-success == 'true' &&
      github.event_name == 'workflow_dispatch' &&
      github.event.inputs.action == 'plan-and-apply'
    environment: 
      name: production-apply-approval
    steps:
      - name: Production Apply Approval Required
        run: |
          echo "## üîí Production Apply Approval" >> $GITHUB_STEP_SUMMARY
          echo "This step requires manual approval before applying changes to production." >> $GITHUB_STEP_SUMMARY
          echo "Please review the terraform plan and approve if the changes are correct." >> $GITHUB_STEP_SUMMARY
          echo "approved=true" >> $GITHUB_OUTPUT
  promote-infrastructure:
    name: Promote Infrastructure
    runs-on: ubuntu-latest
    needs: [determine-environment, deploy]
    if: |
      always() && 
      needs.deploy.outputs.deploy-success == 'true' &&
      (
        (github.event_name == 'workflow_dispatch' && github.event.inputs.create_promotion_pr == 'true') ||
        (github.event_name == 'push' && (github.ref_name == 'dev' || github.ref_name == 'staging'))
      ) &&
      (github.event_name != 'workflow_dispatch' || github.event.inputs.action != 'destroy')
    outputs:
      promotion_created: ${{ steps.promotion.outputs.skip_promotion == 'false' }}
      source_env: ${{ steps.promotion.outputs.source_env }}
      target_env: ${{ steps.promotion.outputs.target_env }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PRIVATE_REPO_TOKEN }}
          fetch-depth: 0

      - name: Setup Git
        run: |
          git config --global user.email "github-actions@github.com"
          git config --global user.name "GitHub Actions"
      - name: Determine promotion target
        id: promotion
        run: |
          SOURCE_ENV="${{ needs.determine-environment.outputs.environment }}"
          
          case $SOURCE_ENV in
            "dev") TARGET_ENV="staging" ;;
            "staging") TARGET_ENV="production" ;;
            "production") TARGET_ENV="" ;;
            *) TARGET_ENV="" ;;
          esac
          
          echo "source_env=$SOURCE_ENV" >> $GITHUB_OUTPUT
          echo "target_env=$TARGET_ENV" >> $GITHUB_OUTPUT
          
          if [ -z "$TARGET_ENV" ]; then
            echo "No promotion target for $SOURCE_ENV environment"
            echo "skip_promotion=true" >> $GITHUB_OUTPUT
          else
            echo "Promotion: $SOURCE_ENV ‚Üí $TARGET_ENV"
            echo "skip_promotion=false" >> $GITHUB_OUTPUT
          fi
      - name: Create repository labels
        if: steps.promotion.outputs.skip_promotion == 'false'
        run: |
          gh label create "promotion" --description "Infrastructure promotion PR" --color "0052cc" || true
          gh label create "infrastructure" --description "Infrastructure changes" --color "1d76db" || true
          gh label create "automated" --description "Automated PR" --color "0e8a16" || true
          gh label create "dev" --description "Development environment" --color "fbca04" || true
          gh label create "staging" --description "Staging environment" --color "ff9500" || true
          gh label create "production" --description "Production environment" --color "d73a49" || true
        env:
          GH_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Create promotion PR
        if: steps.promotion.outputs.skip_promotion == 'false'
        run: |
          SOURCE_ENV="${{ steps.promotion.outputs.source_env }}"
          TARGET_ENV="${{ steps.promotion.outputs.target_env }}"
          
          PR_BODY="## üöÄ Infrastructure Promotion
          **Source Environment:** $SOURCE_ENV
          **Target Environment:** $TARGET_ENV
          **Source Commit:** ${{ github.sha }}
          **Workflow Run:** ${{ github.run_id }}
          **Deployment Status:** ‚úÖ $SOURCE_ENV deployment completed successfully

          ### üìã What's Being Promoted

          This PR promotes infrastructure changes from $SOURCE_ENV to $TARGET_ENV.

          ### üöÄ Next Steps

          1. **Review** all infrastructure changes
          2. **Approve and merge** to trigger $TARGET_ENV deployment

          ---
          *This PR was created automatically after successful $SOURCE_ENV deployment.*"
          
          EXISTING_PR=$(gh pr list --base $TARGET_ENV --head $SOURCE_ENV --json number --jq '.[0].number' 2>/dev/null || echo "")
          
          if [ -n "$EXISTING_PR" ]; then
            echo "PR already exists: #$EXISTING_PR"
            echo "Updating existing PR..."
            echo "$PR_BODY" | gh pr edit $EXISTING_PR --title "üöÄ Promote infrastructure: $SOURCE_ENV ‚Üí $TARGET_ENV" --body-file -
          else
            echo "Creating new PR..."
            echo "$PR_BODY" | gh pr create \
              --base $TARGET_ENV \
              --head $SOURCE_ENV \
              --title "üöÄ Promote infrastructure: $SOURCE_ENV ‚Üí $TARGET_ENV" \
              --body-file - \
              --label "promotion,$TARGET_ENV,infrastructure,automated"
          fi
        env:
          GH_TOKEN: ${{ secrets.PRIVATE_REPO_TOKEN }}

      - name: Add promotion summary
        if: steps.promotion.outputs.skip_promotion == 'false'
        run: |
          echo "## üöÄ Promotion Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Source Environment:** ${{ steps.promotion.outputs.source_env }}" >> $GITHUB_STEP_SUMMARY
          echo "**Target Environment:** ${{ steps.promotion.outputs.target_env }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ **Status:** Promotion PR created successfully" >> $GITHUB_STEP_SUMMARY
          echo "üìã **Next Step:** Review and merge the PR to deploy to ${{ steps.promotion.outputs.target_env }}" >> $GITHUB_STEP_SUMMARY
      - name: No promotion needed
        if: steps.promotion.outputs.skip_promotion == 'true'
        run: |
          echo "## ‚ÑπÔ∏è No Promotion Available" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ steps.promotion.outputs.source_env }}" >> $GITHUB_STEP_SUMMARY
          echo "**Reason:** This is the final environment in the promotion chain" >> $GITHUB_STEP_SUMMARY
  workflow-summary:
    name: Workflow Summary
    runs-on: ubuntu-latest
    needs: [determine-environment, deploy, promote-infrastructure, terraform-destroy, cleanup-and-retry-destroy]
    if: |
      always() && 
      (
        (needs.deploy.result != 'skipped') ||
        (needs.terraform-destroy.result != 'skipped') ||
        (needs.cleanup-and-retry-destroy.result != 'skipped')
      )
    steps:
      - name: Generate workflow summary
        run: |
          echo "## üöÄ Terraform Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ needs.determine-environment.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "**Trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.deploy.result }}" = "success" ]; then
            echo "‚úÖ **Deploy Status:** Successful" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå **Deploy Status:** Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.promote-infrastructure.result }}" = "success" ]; then
            echo "‚úÖ **Promotion Status:** Successful" >> $GITHUB_STEP_SUMMARY
            if [ "${{ needs.promote-infrastructure.outputs.promotion_created }}" = "true" ]; then
              echo "üìã **Next Step:** Review and merge PR: ${{ needs.promote-infrastructure.outputs.source_env }} ‚Üí ${{ needs.promote-infrastructure.outputs.target_env }}" >> $GITHUB_STEP_SUMMARY
            fi
          elif [ "${{ needs.promote-infrastructure.result }}" = "skipped" ]; then
            echo "‚è≠Ô∏è **Promotion Status:** Skipped" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå **Promotion Status:** Failed" >> $GITHUB_STEP_SUMMARY
          fi